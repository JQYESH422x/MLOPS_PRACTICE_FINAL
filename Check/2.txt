DL 2

import tensorflow as tf
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt
import numpy as np

# Load data
(X_train, y_train), (X_test, y_test) = mnist.load_data()
plt.imshow(X_train[0])
# No description has been provided for this image

# Normalize the data
X_train = X_train / 255.0
X_test = X_test / 255.0

# One hot encoding
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

# Building model
model = Sequential([
    Flatten(input_shape=(28, 28)),
    Dense(126, activation="relu"),
    Dense(64, activation="relu"),
    Dense(10, activation="softmax"),
])
# Warning may be shown for input_shape in Flatten layer

# Compile the model
model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"])

# Model fitting
history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))

# Model evaluation
loss, accuracy = model.evaluate(X_test, y_test)
print("Test loss :", loss)
print("Test accuracy :", accuracy)

# Predictions
y_pred = model.predict(X_test)
print(y_pred[0])
plt.imshow(X_test[0])
print(np.argmax(y_pred[0]))

# Plotting the training history
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Loss Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Accuracy Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.tight_layout()
plt.show()
